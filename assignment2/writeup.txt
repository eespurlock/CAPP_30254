Esther Edith Spurlock (12196692)

CAPP 30254

Assignment 2: Writeup for Machine Learning Pipeline

Assumptions for this assignment:
1: We will have a binary variable that our features will predict. 
2: Our features will have a linear correlation with our variable

Methodology:

The code begins and ends with the pipeline function, whose sole goal is to bring the code together.

Task 1: I began by loading the data given to us in my import_data function

Task 2: From my import_data function, I called the explore_data function which created two dictionaries. One that holds descriptive information about each column and one that expresses the correlation of each column to every other column.

I used the correlation dictionary later in the data cleaning process to determine if a column belongs as a feature and to break ties between potential variable.

Task 3: I cleaned data in two parts of my code: once before identifying the variable and features and once after identifying the variable and feature.

From the import_data function, I called the process_data function. This function deleted columns with more than 1/3 of the values listed as NA as well as columns that had identical data. The data also filled in any remaining NA values with the mean of the column.

After identifying the variable and features, I called the drop_extra_columns functon (still from the import_data function) to delete column we would not use. I then used the continuous_to_discrete function to turn any continuous variable into a discrete variable. Continuous variables were split into 10 bins.

Task 4: From the import_data function I called the generate_var_feat function to create variables and features. First, it identified the variable as the column with a binary variable that is the most correlated with the rest of the data. It then identified features as those columns that have a correlation coefficient > 0.01 with the variable.

After task 4, we left the import_data function and returned to the pipeline function by returning the pandas dataframe we had created with our data, the variable name and the column names of our features.

If the code for the next two tasks looks familiar, it is because I borrowed heavily from the second lab code.

Task 5: I then went to the train_data function. Here, I split the data into testing and training data. Next, I created decision tree models of various depths to test the accuracy at different depths.

Task 6: For each decision tree depth, I called the test_data function to get the accuracy of each decision tree depth. I also used a variety of testing thresholds to see how accurate the data could be.

Finally, I returned a dictionary mapping decision tree depths to their corresponding accuracy back to the pipeline function.

The Verdict:
After running my model across various depths and using various thesholds, I got accuracy scores ranging from 0.94466... to 0.17016.... I have listed my accuracy scores from greatest to least along with their corresponding depths and thresholds.

Based on these results, I can say the following: a depth of 50, 100 or 200 gives os an accuracy above 0.9 at a threshold of 0.01. 

Given that depths of that high are not always practical, the most accurate model at the lowest threshold if a depth of 5 with a threshold of 0.4. However, models with a depth of 5 have the 2nd lowest accuracy score at a threshold of 0.01.

The models with the lowest accuracy were all at a threshold of 0.01 with depths of 1, 5, 10 (going from lowest to greatest accuracy).

While models with depths of 10 and 20 do not do phenominally at a threshold of 0.01, they are not horrible either.

If you can not afford to have depths of 50 or greater, the best choice is probably a depth of 20 or 10. If you need single digits, a depth of 5 will do just fine.

Depth:  5
Threshold:  0.4
Accuracy:  0.9446611409068747

Depth:  5
Threshold:  0.6
Accuracy:  0.9427108727450024

Depth:  10
Threshold:  [0.8, 1.0]
Accuracy:  0.9419795221843004

Depth:  10
Threshold:  0.6
Accuracy:  0.9417357386640663

Depth:  1
Thresholds:  [0.1, 0.4, 0.6, 0.8, 1.0]
Accuracy:  0.9414919551438323

Depth:  5
Thresholds:  [0.8, 1.0]
Accuracy:  0.9414919551438323

Depth:  10
Threshold:  0.4
Accuracy:  0.9405168210628961

Depth:  20
Thresholds:  [0.8, 1.0]
Accuracy:  0.9261335933690883

Depth:  20
Threshold:  0.6
Accuracy:  0.9254022428083861

Depth:  100
Thresholds:  [0.01, 0.1, 0.4, 0.6, 0.8, 1.0]
Accuracy:  0.9107752315943443

Depth:  50
Thresholds:  [0.01, 0.1, 0.4, 0.6, 0.8, 1.0]
Accuracy:  0.908824963432472

Depth:  200
Thresholds:  [0.01, 0.1, 0.4, 0.6, 0.8, 1.0]
Accuracy:  0.9051682106289615

Depth:  5
Threshold:  0.1
Accuracy:  0.9029741589468552

Depth:  20
Threshold:  0.1
Accuracy:  0.9002925402242808

Depth:  10
Threshold:  0.1
Accuracy:  0.8832276938078986

Depth:  20
Threshold:  0.01
Accuracy:  0.7011214041930766

Depth:  10
Threshold:  0.01
Accuracy:  0.3364212579229644

Depth:  5
Threshold:  0.01
Accuracy:  0.1728425158459288

Depth:  1
Threshold:  0.01
Accuracy:  0.17016089712335447



Results of data exploration not used in code:

Name: SeriousDlqin2yrs, dtype: float64
count    41016.000000
mean         0.161400
std          0.367904
min          0.000000
25%          0.000000
50%          0.000000
75%          0.000000
max          1.000000

Name: RevolvingUtilizationOfUnsecuredLines, dtype: float64
count    41016.00000
mean         6.37587
std        221.61895
min          0.00000
25%          0.03431
50%          0.18973
75%          0.66716
max      22000.00000

Name: age, dtype: float64
count    41016.000000
mean        51.683489
std         14.746880
min         21.000000
25%         41.000000
50%         51.000000
75%         62.000000
max        109.000000

Name: zipcode, dtype: float64
count    41016.000000
mean     60623.824166
std         11.984357
min      60601.000000
25%      60618.000000
50%      60625.000000
75%      60629.000000
max      60644.000000

Name: NumberOfTime30-59DaysPastDueNotWorse, dtype: float64
count    41016.000000
mean         0.589233
std          5.205628
min          0.000000
25%          0.000000
50%          0.000000
75%          0.000000
max         98.000000

Name: DebtRatio, dtype: float64
count     41016.000000
mean        331.458137
std        1296.109695
min           0.000000
25%           0.176375
50%           0.369736
75%           0.866471
max      106885.000000

Name: MonthlyIncome, dtype: float64
count    3.304200e+04
mean     6.578996e+03
std      1.344683e+04
min      0.000000e+00
25%      3.333000e+03
50%      5.250000e+03
75%      8.055750e+03
max      1.794060e+06

Name: NumberOfOpenCreditLinesAndLoans, dtype: float64
count    41016.000000
mean         8.403477
std          5.207324
min          0.000000
25%          5.000000
50%          8.000000
75%         11.000000
max         56.000000

Name: NumberOfTimes90DaysLate, dtype: float64
count    41016.000000
mean         0.419592
std          5.190382
min          0.000000
25%          0.000000
50%          0.000000
75%          0.000000
max         98.000000

Name: NumberRealEstateLoansOrLines, dtype: float64
count    41016.000000
mean         1.008801
std          1.153826
min          0.000000
25%          0.000000
50%          1.000000
75%          2.000000
max         32.000000

Name: NumberOfTime60-89DaysPastDueNotWorse, dtype: float64
count    41016.000000
mean         0.371587
std          5.169641
min          0.000000
25%          0.000000
50%          0.000000
75%          0.000000
max         98.000000

Name: NumberOfDependents, dtype: float64
count    39979.000000
mean         0.773231
std          1.121269
min          0.000000
25%          0.000000
50%          0.000000
75%          1.000000
max         13.000000

Columns used for testing and training:

PersonID
SeriousDlqin2yrs
age
zipcode
NumberOfTime30-59DaysPastDueNotWorse
DebtRatio
MonthlyIncome
NumberOfOpenCreditLinesAndLoans
NumberOfTimes90DaysLate
NumberRealEstateLoansOrLines
NumberOfTime60-89DaysPastDueNotWorse
NumberOfDependents
